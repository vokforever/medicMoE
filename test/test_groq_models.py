#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π Groq
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π –∏ –∏—Ö –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ API
"""

import os
import requests
import json
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

def test_groq_models():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π Groq"""
    
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("‚ùå GROQ_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        return False
    
    print("üîë GROQ_API_KEY –Ω–∞–π–¥–µ–Ω")
    print(f"üì° –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π Groq...")
    
    url = "https://api.groq.com/openai/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            models_data = response.json()
            available_models = [model["id"] for model in models_data.get("data", [])]
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π ({len(available_models)} –º–æ–¥–µ–ª–µ–π)")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—à–∏ vision –º–æ–¥–µ–ª–∏
            vision_models = [
                "meta-llama/llama-4-scout-17b-16e-instruct",
                "meta-llama/llama-4-maverick-17b-128e-instruct"
            ]
            
            print("\nüîç –ü—Ä–æ–≤–µ—Ä—è—é vision –º–æ–¥–µ–ª–∏:")
            for model in vision_models:
                if model in available_models:
                    print(f"  ‚úÖ {model} - –î–û–°–¢–£–ü–ù–ê")
                else:
                    print(f"  ‚ùå {model} - –ù–ï –î–û–°–¢–£–ü–ù–ê")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º text –º–æ–¥–µ–ª–∏
            text_models = [
                "llama-3.1-8b-instant",
                "llama-3.3-70b-versatile",
                "meta-llama/llama-guard-4-12b"
            ]
            
            print("\nüîç –ü—Ä–æ–≤–µ—Ä—è—é text –º–æ–¥–µ–ª–∏:")
            for model in text_models:
                if model in available_models:
                    print(f"  ‚úÖ {model} - –î–û–°–¢–£–ü–ù–ê")
                else:
                    print(f"  ‚ùå {model} - –ù–ï –î–û–°–¢–£–ü–ù–ê")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
            print(f"\nüìã –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Groq ({len(available_models)}):")
            for i, model in enumerate(available_models[:20], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
                print(f"  {i:2d}. {model}")
            
            if len(available_models) > 20:
                print(f"  ... –∏ –µ—â–µ {len(available_models) - 20} –º–æ–¥–µ–ª–µ–π")
            
            return True
            
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
            print(f"–û—Ç–≤–µ—Ç: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
        return False

def test_groq_chat():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π —á–∞—Ç —Å Groq"""
    
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("‚ùå GROQ_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–æ—Å—Ç–æ–π —á–∞—Ç —Å Groq...")
    
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "llama-3.1-8b-instant",
        "messages": [
            {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"}
        ],
        "max_tokens": 100
    }
    
    try:
        response = requests.post(url, headers=headers, json=data)
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            print(f"‚úÖ –ß–∞—Ç —É—Å–ø–µ—à–µ–Ω!")
            print(f"üìù –û—Ç–≤–µ—Ç: {content}")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á–∞—Ç–∞: {response.status_code}")
            print(f"–û—Ç–≤–µ—Ç: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á–∞—Ç–µ: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Groq API")
    print("=" * 50)
    
    # –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
    models_ok = test_groq_models()
    
    if models_ok:
        # –¢–µ—Å—Ç 2: –ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç
        chat_ok = test_groq_chat()
        
        if chat_ok:
            print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("\n‚ö†Ô∏è –¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π –ø—Ä–æ—à–µ–ª, –Ω–æ —á–∞—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    else:
        print("\n‚ùå –¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π –Ω–µ –ø—Ä–æ—à–µ–ª")
    
    print("\n" + "=" * 50)
    print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
